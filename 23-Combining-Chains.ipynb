{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10ee12e-8bd3-49a0-ab95-18f538f325ee",
   "metadata": {},
   "source": [
    "![nvidia](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef839d89-455f-4a7e-84d2-8ae05c6d1d26",
   "metadata": {},
   "source": [
    "# Combining Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "399aef03-8b9d-4914-b493-8c9339fb552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from videos.walkthroughs import walkthrough_23 as walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd4ebd9-2c8b-4588-92a2-366af62d6141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video controls width=\"640\" height=\"360\">\n",
       "        <source src=\"https://d36m44n9vdbmda.cloudfront.net/assets/s-fx-12-v2/walkthrough_23.mp4\" type=\"video/mp4\">\n",
       "        Your browser does not support the video tag.\n",
       "    </video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "walkthrough()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28013522",
   "metadata": {},
   "source": [
    "In this notebook you'll learn how to compose multiple LLM-related chains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69366671-11a4-4439-b6ad-cb89497ef5d4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08054f2",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a023bc7a-47b5-4508-957c-f3354c9fb363",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you will:\n",
    "\n",
    "- Learn how to compose chains of chains\n",
    "- Apply your ability to chain meaningful language tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e9ea06-814f-43fd-9f59-ce67dfcb1bbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327550d4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6ed9ec-054e-4a6d-9849-836e47924658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7aca5-1c4a-4cb0-bd28-d8a7636cc96d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e1244",
   "metadata": {},
   "source": [
    "## Create a Model Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c05c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://llama:8000/v1'\n",
    "model = 'meta/llama-3.1-8b-instruct'\n",
    "llm = ChatNVIDIA(base_url=base_url, model=model, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d304e5-6bbe-4beb-ba92-fa208fb4c2f4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f280c-cb9d-40d2-a6de-72d33308364e",
   "metadata": {},
   "source": [
    "## Combining Multiple LLM Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a38cfc0-2292-4d95-ad6c-f660ba2b9a41",
   "metadata": {},
   "source": [
    "If you recall, runnables can be composed into chains, but also, chains are themselves runnables. Therefore, chains can be used to compose larger chains.\n",
    "\n",
    "It's easy to imagine tasks we would like to perform that would require multiple calls to an LLM for the desired end result. We'll begin our exploration of chaining chains with such a scenario, where we will compose multiple LLM chains, piping the output of one chain into the next.\n",
    "\n",
    "To do this we are going to work with the following list of `thesis_statements`. Note: any typos you see in the thesis statements are intentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28575a1-6315-4797-b9f5-1f32680c360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "thesis_statements = [\n",
    "    \"The fundametal concepts quantum physcis are difficult to graps, even for the mostly advanced students.\",\n",
    "    \"Einstein's theroy of relativity revolutionised undrstanding of space and time, making it clear that they are interconnected.\",\n",
    "    \"The first law of thermodynmics states that energy cannot be created or destoryed, excepting only transformed from one form to another.\",\n",
    "    \"Electromagnetism is one of they four funadmental forces of nature, and it describes the interaction between charged particles.\",\n",
    "    \"In the study of mechanic, Newton's laws of motion provide a comprehensive framework for understading the movement of objects under various forces.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24f7b8c-2705-482e-9066-0dec4c85a12d",
   "metadata": {},
   "source": [
    "Our goal is going to be to expand each of these thesis statements into a well-written paragraph, with the thesis statement itself being the first sentence. You may have noticed, however, that each of these thesis statements contains spelling and/or grammar errors that need correcting.\n",
    "\n",
    "Therefore, we are going to create a chain first to address the spelling and grammar issues, and then chain the corrected thesis statements into a second LLM chain responsible for generating the full paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322b5ff-e208-4fd0-9642-792b506a63f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3988eb-3cf4-4149-84bf-51b690bcc675",
   "metadata": {},
   "source": [
    "## Exercise: Create a Spelling and Grammar Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a18ede-b3a8-49b9-baba-68fe58c34428",
   "metadata": {},
   "source": [
    "To begin, create `grammar_chain` which returns its inputs after performing spelling and grammar corrections on them.\n",
    "\n",
    "We already have an LLM instance defined above (`llm`), but you will need to create both a prompt template and output parser to include in your chain.\n",
    "\n",
    "You may need to develop your prompt template iteratively. Make sure especially that the chain returns only the corrected text, and not any additional comments etc. from the model.\n",
    "\n",
    "Test your chain by sending it the batch of `thesis_statements` defined above.\n",
    "\n",
    "Check out the solution below if you get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad94e5d-9e4b-4cf6-9801-dc7a10d09e79",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ecf9fff-fd46-4132-838e-07267eab288a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting grammar correction batch...\n",
      "INFO:__main__:Grammar correction batch completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: This is an example sentence that need correction.\n",
      "Corrected: This is an example sentence that needs correction.\n",
      "--------------------------------------------------\n",
      "Original: They was going to the market when I seen them.\n",
      "Corrected: They were going to the market when I saw them.\n",
      "--------------------------------------------------\n",
      "Original: Its important to understand how AI works in today's world.\n",
      "Corrected: It's important to understand how AI works in today's world.\n",
      "--------------------------------------------------\n",
      "Original: The cat chased it's tail until it were tired.\n",
      "Corrected: The cat chased its tail until it was tired.\n",
      "--------------------------------------------------\n",
      "Original: We was planning a trip to the mountain's next summer.\n",
      "Corrected: We are planning a trip to the mountains next summer.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Optional: Normalize inputs (e.g., strip whitespace, unify case if needed)\n",
    "def normalize_text(text):\n",
    "    normalized = text.strip()\n",
    "    logger.debug(f\"Normalized text: {normalized}\")\n",
    "    return normalized\n",
    "\n",
    "# Define the grammar correction prompt\n",
    "def grammar_prompt(text):\n",
    "    return (\n",
    "        f\"Please correct any spelling or grammar mistakes in the following sentence. \"\n",
    "        f\"Return ONLY the corrected sentence, with no extra commentary:\\n\\n\"\n",
    "        f\"{text}\"\n",
    "    )\n",
    "\n",
    "# Define the parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Compose the grammar chain\n",
    "grammar_chain = (\n",
    "    RunnableLambda(normalize_text) |\n",
    "    RunnableLambda(grammar_prompt) |\n",
    "    llm |  # assumed to be defined and connected in your environment\n",
    "    parser\n",
    ")\n",
    "\n",
    "def run_grammar_batch(statements):\n",
    "    corrected_statements = []\n",
    "    try:\n",
    "        logger.info(\"Starting grammar correction batch...\")\n",
    "        corrected_statements = grammar_chain.batch(statements)\n",
    "        logger.info(\"Grammar correction batch completed successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during grammar correction batch: {e}\")\n",
    "    return corrected_statements\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    thesis_statements = [\n",
    "        \"This is an example sentence that need correction.\",\n",
    "        \"They was going to the market when I seen them.\",\n",
    "        \"Its important to understand how AI works in today's world.\",\n",
    "        \"The cat chased it's tail until it were tired.\",\n",
    "        \"We was planning a trip to the mountain's next summer.\"\n",
    "    ]\n",
    "\n",
    "    corrected = run_grammar_batch(thesis_statements)\n",
    "    for original, fixed in zip(thesis_statements, corrected):\n",
    "        print(f\"Original: {original}\\nCorrected: {fixed}\\n{'-'*50}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f763b-6c8d-48fd-8a65-032c043a3734",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a4733-1f33-4647-8689-28d936254145",
   "metadata": {},
   "source": [
    "We begin by engineering a prompt for spelling and grammar correction. We take care to be specific in our prompt that the model should generate only the corrected text with no addional comment or preface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ebb42-05b2-4aa6-8e2c-df3894b84fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spelling_and_grammar_template = ChatPromptTemplate.from_template(\"\"\"Fix any spelling or grammatical issues in the following text. Return \\\n",
    "back the correct text and only the corrected text with no additional comment or preface. Text: {text}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa997937-5c07-4844-a864-856cbb34015e",
   "metadata": {},
   "source": [
    "Next we create an instance of a string output parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab44b7e8-bbee-43cd-b40c-43e35b9cb77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84eb9ed-331a-403b-9b1b-5b821571a562",
   "metadata": {},
   "source": [
    "All that's left to do is compose the chain..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad697c9c-3914-45b7-8052-25a6cf2409da",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_chain = spelling_and_grammar_template | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802ddbd-a274-4e3b-beb5-fb1cf07f47db",
   "metadata": {},
   "source": [
    "...and pass the thesis statements to it in batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7306ab2-752d-4699-9dac-0486b4e1571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_texts = grammar_chain.batch(thesis_statements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a6cfdb-edab-445b-a97d-95d1db5d2a51",
   "metadata": {},
   "source": [
    "Looking at the corrected outputs, it appears that the model did an excellent job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefeaa99-5b8b-4c52-b3d1-23a624ab1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "for corrected_text in corrected_texts:\n",
    "    print(corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89251e0d-895d-4ee3-9b84-94d9618f3af9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fd3022-dcb1-4f42-b055-439d0825784d",
   "metadata": {},
   "source": [
    "## Exercise: Create a Paragraph Generator Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5de3f1-11b7-4f83-92b9-41d3a516dd33",
   "metadata": {},
   "source": [
    "Create a second chain called `paragraph_generator_chain`. Given a sentence as input, it should use that sentence as the first sentence of a paragraph which it should generate.\n",
    "\n",
    "**Note:** this chain should not contain any grammar or spell checking functionality. The chain should be responsible only for the paragraph generation task.\n",
    "\n",
    "Test your chain by sending it the batch of `thesis_statements` defined above.\n",
    "\n",
    "Feel free to check out the *Solution* below if you get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d619976-b894-4070-8d06-0be25928c1a8",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d442b6d-879f-406e-96ed-45ca14da1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_generator_chain = 'TODO'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e89dcd-c8c7-4756-92a1-53bba9c09e05",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8419f223-5722-4e37-a013-5e465ab617df",
   "metadata": {},
   "source": [
    "We begin the task by engineering a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66420078-2582-4b2b-b86e-7bdf68a722be",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_generator_template = ChatPromptTemplate.from_template(\"\"\"Generate a 4 to 8 sentence paragraph that begins with the following \\\n",
    "thesis statement. Return back the paragraph and only the paragraph with no additional comment or preface. Thesis statement: {thesis}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7b5a2-977f-4a9d-9d95-4e192962959a",
   "metadata": {},
   "source": [
    "Since we already have a model instance and parser, all we have to do is compose the chain..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ec6c2-061c-471a-8fbf-ddfc443fb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_generator_chain = paragraph_generator_template | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d21adf-4048-4438-9769-941722980f6f",
   "metadata": {},
   "source": [
    "...and send it the batch of thesis statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0304797-53b6-4d32-b1e4-f31f5ff36566",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = paragraph_generator_chain.batch(thesis_statements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a065a49c-3ba2-4056-b3fe-ec81c1ef9cc1",
   "metadata": {},
   "source": [
    "Looking at the generated paragraphs, it looks like the model did a great job.\n",
    "\n",
    "It's worth highlighing that even though we did not prompt the model to address spelling and grammar mistakes, it did fix some of the spelling mistakes anyway, however, it's clear that most of the grammar errors from the thesis statements we passed in are still present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6e969-e805-4809-a898-8b178cdbd3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paragraph in paragraphs:\n",
    "    print(paragraph+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6441e0-58e8-48cd-a0e0-99ac3b5fe76a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260a8de-e4ed-4aa8-b3e2-cabb6669ef1b",
   "metadata": {},
   "source": [
    "## Exercise: Create a Chain of Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dac355d-b031-47a6-9ee5-a4a7839fde58",
   "metadata": {},
   "source": [
    "Reusing the chains you've already created, create a `corrected_generator_chain` that uses the LLM first to perform spelling and grammar corrections on `thesis_statements` before then generating full paragraphs based the (corrected) thesis statements.\n",
    "\n",
    "You don't need to overthink this. Just remember, chains are runnables, and can be piped together just like any other runnable.\n",
    "\n",
    "Test your chain by sending it the batch of `thesis_statements` defined above.\n",
    "\n",
    "Feel free to check out the *Solution* below if you get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bcc334-cd28-46c3-9e2c-78757a6496ae",
   "metadata": {},
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f86acf06-0ecf-4cc2-b1fc-ed708e8d548a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting paragraph generation batch...\n",
      "INFO:__main__:Paragraph generation batch completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thesis: Artificial intelligence will transform the job market.\n",
      "Paragraph:\n",
      "The rapid advancement of artificial intelligence (AI) is poised to revolutionize the job market in profound ways, with far-reaching consequences for workers, employers, and the economy as a whole. As AI systems become increasingly sophisticated, they will automate many routine and repetitive tasks, freeing up human workers to focus on higher-level tasks that require creativity, problem-solving, and emotional intelligence. This shift will lead to the creation of new job categories and industries that we cannot yet imagine, but it will also displace many jobs that are currently performed by humans. According to a report by the McKinsey Global Institute, up to 800 million jobs could be lost worldwide due to automation by 2030, while 140 million new jobs may be created. However, the impact of AI on the job market will not be uniform, with some industries and occupations being more susceptible to automation than others. For example, jobs that involve tasks such as data entry, bookkeeping, and customer service are likely to be heavily automated, while jobs that require human empathy, creativity, and complex problem-solving skills will be less likely to be replaced by machines. As AI transforms the job market, it is essential for workers, policymakers, and educators to adapt and prepare for the changing landscape, investing in education and training programs that focus on developing the skills that are most valuable in an AI-driven economy.\n",
      "============================================================\n",
      "\n",
      "Thesis: Climate change poses a serious threat to coastal cities.\n",
      "Paragraph:\n",
      "Climate change poses a serious threat to coastal cities. Rising sea levels, more frequent and intense storms, and increased flooding are just a few of the consequences of a warming planet that coastal cities are facing. As the polar ice caps melt and glaciers retreat, the global sea level is projected to rise by up to 1 meter by 2100, threatening to inundate coastal areas and low-lying cities. This will not only displace millions of people but also put a strain on the infrastructure and economy of these cities. Coastal cities such as Miami, New York, and Bangkok are already experiencing the effects of sea level rise, with frequent flooding and saltwater contamination of freshwater sources. The economic costs of these impacts are significant, with estimates suggesting that the global cost of climate-related disasters could reach $1 trillion by 2050. Furthermore, the loss of coastal ecosystems and biodiversity will have far-reaching consequences for the health and well-being of urban residents. As the world's population continues to urbanize, it is essential that we take immediate action to mitigate the effects of climate change and protect our coastal cities from the devastating impacts of a changing climate.\n",
      "============================================================\n",
      "\n",
      "Thesis: Online education offers flexibility but requires discipline.\n",
      "Paragraph:\n",
      "Online education offers flexibility but requires discipline. This dichotomy is a fundamental aspect of the online learning experience, as students must balance the freedom to learn at their own pace with the need to stay on track and meet deadlines. On one hand, online courses provide the flexibility to attend classes from anywhere, at any time, allowing students to fit their education into their busy schedules. This flexibility is particularly beneficial for working professionals, parents, and individuals with caregiving responsibilities, who may not have the luxury of attending traditional on-campus classes. However, this flexibility also requires discipline, as students must be self-motivated and able to stay organized and focused without the structure and accountability of a traditional classroom environment. Without discipline, students may struggle to stay on top of coursework, leading to poor grades and a lack of progress towards their academic goals. Ultimately, the key to success in online education is finding a balance between flexibility and discipline, and being able to adapt to the unique demands of online learning. By doing so, students can reap the benefits of online education while achieving their academic objectives.\n",
      "============================================================\n",
      "\n",
      "Thesis: Renewable energy investments are crucial for the future.\n",
      "Paragraph:\n",
      "Renewable energy investments are crucial for the future as they provide a sustainable solution to the world's growing energy demands while mitigating the devastating effects of climate change. The increasing global energy consumption has led to a significant rise in greenhouse gas emissions, primarily due to the reliance on fossil fuels. Investing in renewable energy sources such as solar, wind, and hydroelectric power can help reduce our carbon footprint and transition towards a cleaner and more environmentally friendly energy mix. Moreover, renewable energy investments can create jobs, stimulate local economies, and improve energy security by reducing dependence on imported fuels. Furthermore, the cost of renewable energy technologies has decreased dramatically over the years, making them more competitive with fossil fuels and paving the way for widespread adoption. As governments and corporations increasingly recognize the importance of renewable energy, investments in this sector are expected to surge, driving innovation and growth in the industry. By prioritizing renewable energy investments, we can ensure a sustainable future for generations to come and avoid the catastrophic consequences of climate change.\n",
      "============================================================\n",
      "\n",
      "Thesis: Urban gardening promotes sustainability and community engagement.\n",
      "Paragraph:\n",
      "Urban gardening promotes sustainability and community engagement. By cultivating gardens in urban areas, individuals can reduce their reliance on industrial agriculture and transportation, thereby decreasing their carbon footprint. Additionally, urban gardens provide a space for community members to come together and share knowledge, resources, and labor, fostering a sense of community and social connection. This collective effort not only beautifies the urban landscape but also increases food security and access to fresh produce, particularly in areas where grocery stores are scarce. Furthermore, urban gardens can serve as educational platforms, teaching children and adults alike about sustainable practices, nutrition, and environmental stewardship. As urban gardening initiatives grow, they can also contribute to the revitalization of neglected spaces, transforming vacant lots and abandoned buildings into vibrant green oases. By promoting urban gardening, cities can become more livable, resilient, and environmentally conscious, setting a positive example for other communities to follow.\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define robust paragraph generation prompt\n",
    "def paragraph_prompt(thesis):\n",
    "    return (\n",
    "        f\"Using the following thesis statement as the first sentence, generate a coherent, well-structured, \"\n",
    "        f\"4 to 8 sentence paragraph expanding on its ideas. \"\n",
    "        f\"ONLY return the paragraph, no commentary, no preface, no explanations.\\n\\n\"\n",
    "        f\"Thesis statement: {thesis}\"\n",
    "    )\n",
    "\n",
    "# Create the prompt template (if using LangChain templates)\n",
    "paragraph_generator_template = RunnableLambda(paragraph_prompt)\n",
    "\n",
    "# Define the parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Compose the chain\n",
    "paragraph_generator_chain = paragraph_generator_template | llm | parser\n",
    "\n",
    "def run_paragraph_batch(thesis_statements):\n",
    "    paragraphs = []\n",
    "    try:\n",
    "        logger.info(\"Starting paragraph generation batch...\")\n",
    "        paragraphs = paragraph_generator_chain.batch(thesis_statements)\n",
    "        logger.info(\"Paragraph generation batch completed successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during paragraph generation batch: {e}\")\n",
    "    return paragraphs\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    thesis_statements = [\n",
    "        \"Artificial intelligence will transform the job market.\",\n",
    "        \"Climate change poses a serious threat to coastal cities.\",\n",
    "        \"Online education offers flexibility but requires discipline.\",\n",
    "        \"Renewable energy investments are crucial for the future.\",\n",
    "        \"Urban gardening promotes sustainability and community engagement.\"\n",
    "    ]\n",
    "\n",
    "    paragraphs = run_paragraph_batch(thesis_statements)\n",
    "    for thesis, paragraph in zip(thesis_statements, paragraphs):\n",
    "        print(f\"Thesis: {thesis}\\nParagraph:\\n{paragraph}\\n{'='*60}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf8db8-1bb1-4a87-a0ba-1b256869eeda",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7254860-cc9c-4e3a-8239-0eb9bfbcf79a",
   "metadata": {},
   "source": [
    "All we have to do to create our larger chain is to pipe together the 2 chains we already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e24624a-75f0-4be3-bac7-8b5a08ab2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_generator_chain = grammar_chain | paragraph_generator_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942bd325-568b-472d-8614-73660ba014cb",
   "metadata": {},
   "source": [
    "Just because it will be interesting, we can take a look at the computational graph for our new chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01905d2-8dc4-4ada-a541-05a7b8256989",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corrected_generator_chain.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce621ec-58b0-41cb-86e8-cd6ad24eec4b",
   "metadata": {},
   "source": [
    "We can batch send our thesis statements to this larger chain just as we did with the smaller chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81fdff0-04e6-4951-b1e6-ea1201d7e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = corrected_generator_chain.batch(thesis_statements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab3cd31-5254-42c0-bb6c-fa3cf576e5c1",
   "metadata": {},
   "source": [
    "Looking at the final outputs we can see that the paragraphs were well-generated, but also, that all the spelling and grammar mistakes in the original thesis statements have been addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852e24f-6ded-4328-b6db-6f4b2098d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paragraph in paragraphs:\n",
    "    print(paragraph+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0812b58-3226-4a6c-b8dd-d6fc3a6398a2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12727284-4be0-4a93-a34d-fcff3443f784",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cb5233-a5f4-491c-9db9-ca7d5a31bb95",
   "metadata": {},
   "source": [
    "In this notebook you learned to treat chains as the runnable they are and combine them together, including in ways that allowed you to leverage LLMs multiple times to accomplish a desired task.\n",
    "\n",
    "In the next notebook you'll continue on the theme of chain composition, but this time focusing on the ability to create and utilize parallel chains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
